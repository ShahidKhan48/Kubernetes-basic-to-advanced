# Basic Job
apiVersion: batch/v1
kind: Job
metadata:
  name: basic-job
  namespace: default
  labels:
    app: basic-job
spec:
  # Number of successful completions needed
  completions: 1
  
  # Number of pods to run in parallel
  parallelism: 1
  
  # Number of retries before marking job as failed
  backoffLimit: 3
  
  # Time limit for job completion
  activeDeadlineSeconds: 300
  
  template:
    metadata:
      labels:
        app: basic-job
    spec:
      restartPolicy: Never
      containers:
      - name: job-container
        image: busybox:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Job started at $(date)"
          echo "Processing data..."
          sleep 30
          echo "Job completed at $(date)"
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"

---
# Parallel Job
apiVersion: batch/v1
kind: Job
metadata:
  name: parallel-job
  namespace: default
  labels:
    app: parallel-job
spec:
  completions: 6
  parallelism: 3
  backoffLimit: 2
  template:
    metadata:
      labels:
        app: parallel-job
    spec:
      restartPolicy: Never
      containers:
      - name: worker
        image: busybox:latest
        command:
        - /bin/sh
        - -c
        - |
          WORKER_ID=$(hostname | grep -o '[0-9]*$')
          echo "Worker $WORKER_ID started at $(date)"
          # Simulate work
          sleep $((10 + RANDOM % 20))
          echo "Worker $WORKER_ID completed at $(date)"
        resources:
          requests:
            memory: "32Mi"
            cpu: "25m"
          limits:
            memory: "64Mi"
            cpu: "50m"

---
# Job with Init Container
apiVersion: batch/v1
kind: Job
metadata:
  name: job-with-init
  namespace: default
spec:
  template:
    spec:
      restartPolicy: Never
      initContainers:
      - name: setup
        image: busybox:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Setting up environment..."
          mkdir -p /shared/data
          echo "Setup completed" > /shared/data/setup.txt
        volumeMounts:
        - name: shared-data
          mountPath: /shared
      containers:
      - name: main-job
        image: busybox:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Main job started"
          cat /shared/data/setup.txt
          echo "Processing with setup data..."
          sleep 20
          echo "Main job completed"
        volumeMounts:
        - name: shared-data
          mountPath: /shared
      volumes:
      - name: shared-data
        emptyDir: {}

---
# Basic CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: basic-cronjob
  namespace: default
  labels:
    app: basic-cronjob
spec:
  # Run every 5 minutes
  schedule: "*/5 * * * *"
  
  # Timezone (optional)
  timeZone: "UTC"
  
  # Job history limits
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  
  # Concurrency policy
  concurrencyPolicy: Allow
  
  # Starting deadline
  startingDeadlineSeconds: 100
  
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 120
      template:
        metadata:
          labels:
            app: basic-cronjob
        spec:
          restartPolicy: OnFailure
          containers:
          - name: cronjob-container
            image: busybox:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "CronJob execution started at $(date)"
              echo "Performing scheduled task..."
              sleep 10
              echo "CronJob execution completed at $(date)"
            resources:
              requests:
                memory: "32Mi"
                cpu: "25m"
              limits:
                memory: "64Mi"
                cpu: "50m"

---
# Database Backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup-cronjob
  namespace: default
  labels:
    app: database-backup
spec:
  # Run daily at 2 AM
  schedule: "0 2 * * *"
  timeZone: "UTC"
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 300
  
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 3600
      template:
        metadata:
          labels:
            app: database-backup
        spec:
          restartPolicy: Never
          containers:
          - name: backup-container
            image: mysql:8.0
            env:
            - name: MYSQL_HOST
              value: "mysql-service"
            - name: MYSQL_USER
              value: "backup_user"
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: backup-password
            - name: BACKUP_DATE
              value: "$(date +%Y%m%d_%H%M%S)"
            command:
            - /bin/bash
            - -c
            - |
              echo "Starting database backup at $(date)"
              
              # Create backup directory
              mkdir -p /backup
              
              # Perform database backup
              mysqldump -h $MYSQL_HOST -u $MYSQL_USER -p$MYSQL_PASSWORD \
                --all-databases --single-transaction --routines --triggers \
                > /backup/backup_$(date +%Y%m%d_%H%M%S).sql
              
              if [ $? -eq 0 ]; then
                echo "Database backup completed successfully at $(date)"
                ls -la /backup/
              else
                echo "Database backup failed at $(date)"
                exit 1
              fi
            
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            
            resources:
              requests:
                memory: "256Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "200m"
          
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc

---
# Log Cleanup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-cleanup-cronjob
  namespace: default
spec:
  # Run weekly on Sunday at 3 AM
  schedule: "0 3 * * 0"
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 1
  concurrencyPolicy: Replace
  
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: log-cleanup
            image: busybox:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting log cleanup at $(date)"
              
              # Find and delete log files older than 30 days
              find /var/log -name "*.log" -type f -mtime +30 -delete
              
              # Find and delete compressed logs older than 90 days
              find /var/log -name "*.gz" -type f -mtime +90 -delete
              
              echo "Log cleanup completed at $(date)"
              
              # Show remaining disk space
              df -h /var/log
            
            volumeMounts:
            - name: log-volume
              mountPath: /var/log
            
            securityContext:
              runAsUser: 0
              runAsGroup: 0
          
          volumes:
          - name: log-volume
            hostPath:
              path: /var/log
              type: Directory

---
# Report Generation CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: report-generation-cronjob
  namespace: default
spec:
  # Run on weekdays at 6 AM
  schedule: "0 6 * * 1-5"
  timeZone: "America/New_York"
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 2
  concurrencyPolicy: Forbid
  
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 1800
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: report-generator
            image: python:3.9-slim
            env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: database-secret
                  key: url
            - name: EMAIL_SERVER
              valueFrom:
                configMapKeyRef:
                  name: email-config
                  key: server
            - name: REPORT_DATE
              value: "$(date +%Y-%m-%d)"
            
            command:
            - /bin/bash
            - -c
            - |
              echo "Starting report generation at $(date)"
              
              # Install required packages
              pip install psycopg2-binary pandas openpyxl
              
              # Generate report
              python3 << 'EOF'
              import pandas as pd
              import os
              from datetime import datetime
              
              print("Connecting to database...")
              # Database connection and report generation logic here
              print("Report generated successfully")
              
              # Save report
              report_date = os.environ.get('REPORT_DATE', datetime.now().strftime('%Y-%m-%d'))
              filename = f"/reports/daily_report_{report_date}.xlsx"
              
              # Create sample report
              df = pd.DataFrame({'Date': [report_date], 'Status': ['Generated']})
              df.to_excel(filename, index=False)
              print(f"Report saved to {filename}")
              EOF
              
              echo "Report generation completed at $(date)"
            
            volumeMounts:
            - name: reports-storage
              mountPath: /reports
            
            resources:
              requests:
                memory: "512Mi"
                cpu: "250m"
              limits:
                memory: "1Gi"
                cpu: "500m"
          
          volumes:
          - name: reports-storage
            persistentVolumeClaim:
              claimName: reports-pvc

---
# PVC for Backup Storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
  namespace: default
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
# PVC for Reports Storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: reports-pvc
  namespace: default
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi